{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a min GPT with Transformer\n",
    "\n",
    "> Reference :-\n",
    "* [Welsh Labs YT Video : How DeepSeek Rewrote the Transformer [MLA]](https://youtu.be/0VLAoVGf_74)\n",
    "* [Arxiv Paper : DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/pdf/2405.04434)\n",
    "* [SimpleGPT](SimpleGPT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(8745)\n",
    "batch_size = 32 # batch size\n",
    "block_size = 16 # context length (number of tokens in the input)\n",
    "embed_size = 32 # embedding size of the Q, K, V\n",
    "num_heads = 4 # number of heads in the multi-head attention\n",
    "num_layers = 4 # number of transformer blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of data = 1115394\n",
      "\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# the tiny shakespeare dataset\n",
    "# check if the file exists\n",
    "import os\n",
    "if not os.path.exists(\"input.txt\"):\n",
    "    print(\"Downloading the dataset...\")\n",
    "    !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt \n",
    "\n",
    "# read the file and display some lines\n",
    "data = \"\"\n",
    "with open('input.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(f\"len of data = {len(data)}\\n\")\n",
    "print(data[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the vocabulary from the data (Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab_size=65\n",
      "[20, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]\n",
      "Hello there\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary\n",
    "vocab = sorted(list(set(data)))\n",
    "\n",
    "print(\"\".join(vocab))\n",
    "vocab_size = len(vocab)\n",
    "print(f\"{vocab_size=}\")\n",
    "\n",
    "# Tokenize\n",
    "stoi = {char:i for i, char in enumerate(vocab)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda s: \"\".join([itos[c] for c in s]) # you just return a string\n",
    "\n",
    "print(encode(\"Hello there\"))\n",
    "print(decode(encode(\"Hello there\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Train, Test split and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data)=1003854, len(val_data)=111540\n",
      "X torch.Size([32, 16])\n",
      "Y torch.Size([32, 16])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_t = torch.tensor(encode(data), dtype=torch.long)\n",
    "data_t = data_t.to(device)\n",
    "\n",
    "# train test split\n",
    "n = int(0.9*len(data_t))\n",
    "train_data = data_t[:n]\n",
    "val_data = data_t[n:]\n",
    "\n",
    "print(f\"{len(train_data)=}, {len(val_data)=}\")\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    random_indices = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in random_indices])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in random_indices])\n",
    "    return x, y\n",
    "\n",
    "sample_X, sample_Y = get_batch(\"train\")\n",
    "print(\"X\", sample_X.shape)\n",
    "print(\"Y\", sample_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation (Multi-Head Latent Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type (var_name))                       Output Shape              Param #\n",
       "===============================================================================================\n",
       "SimpleDeepseek (SimpleDeepseek)               [32, 16, 65]              --\n",
       "├─Embedding (token_embedding_table)           [32, 16, 32]              2,080\n",
       "├─Embedding (position_embedding_table)        [16, 32]                  512\n",
       "├─Sequential (blocks)                         [32, 16, 32]              --\n",
       "│    └─Block (0)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "│    └─Block (1)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "│    └─Block (2)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "│    └─Block (3)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 8]               256\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              256\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "├─LayerNorm (ln_f)                            [32, 16, 32]              64\n",
       "├─Linear (lm_head)                            [32, 16, 65]              2,145\n",
       "===============================================================================================\n",
       "Total params: 47,937\n",
       "Trainable params: 47,937\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.53\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 6.56\n",
       "Params size (MB): 0.19\n",
       "Estimated Total Size (MB): 6.76\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class MultiHeadLatentAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, block_size):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_size = embed_size\n",
    "        self.block_size = block_size\n",
    "        self.head_size = embed_size // num_heads # 32 / 8 = 4\n",
    "        self.latent_size = embed_size // 4 # 32 / 8 = 4\n",
    "\n",
    "        # Down-Project (embed_size -> latent_size) : Shared across heads\n",
    "        self.W_DQ = nn.Linear(embed_size, self.latent_size, bias=False)\n",
    "        self.W_DKV = nn.Linear(embed_size, self.latent_size, bias=False)\n",
    "\n",
    "        # (Concatenated (head_size * num_heads) -> embed_size) : Shared across heads\n",
    "        self.W_O = nn.Linear(self.head_size * num_heads, embed_size, bias=False)\n",
    "\n",
    "        # Up-Project (latent_size -> head_size) * num_heads : Head specific\n",
    "        self.W_UQ = nn.Linear(self.latent_size, self.head_size * num_heads, bias=False)\n",
    "        self.W_UK = nn.Linear(self.latent_size, self.head_size * num_heads, bias=False)\n",
    "        self.W_UV = nn.Linear(self.latent_size, self.head_size * num_heads, bias=False)\n",
    "\n",
    "        # Masking : Shared across heads\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dsqrt = self.head_size ** 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, Emb = x.shape\n",
    "\n",
    "        # Down-Project (embed_size -> latent_size)\n",
    "        c_Qt = self.W_DQ(x) # B, T, latent_size\n",
    "        c_KVt = self.W_DKV(x) # B, T, latent_size\n",
    "\n",
    "        # Up-Project (latent_size -> head_size) * num_heads\n",
    "        q_Cti = self.W_UQ(c_Qt).view(B, T, self.num_heads, self.head_size) # B, T, num_heads, head_size\n",
    "        k_Cti = self.W_UK(c_KVt).view(B, T, self.num_heads, self.head_size) # B, T, num_heads, head_size\n",
    "        v_Cti = self.W_UV(c_KVt).view(B, T, self.num_heads, self.head_size) # B, T, num_heads, head_size\n",
    "\n",
    "        # (B, T, num_heads, head_size) -> (B, num_heads, T, head_size) for QK matrix multiplication\n",
    "        q_Cti = q_Cti.permute(0, 2, 1, 3)\n",
    "        k_Cti = k_Cti.permute(0, 2, 1, 3)\n",
    "        v_Cti = v_Cti.permute(0, 2, 1, 3)\n",
    "\n",
    "        # Attention : QK^T / sqrt(head_size)\n",
    "        att = (q_Cti @ k_Cti.transpose(-2, -1)) / self.dsqrt # B, num_heads, T, T\n",
    "        att = att.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        O_ti = att @ v_Cti # B, num_heads, T, head_size\n",
    "\n",
    "        # B, num_heads, T, head_size -> B, T, num_heads, head_size -> B, T, embed_size\n",
    "        O_t = O_ti.permute(0, 2, 1, 3).reshape(B, T, -1)\n",
    "        # (Concatenated (heads * head_size) -> embed_size)\n",
    "        u_t = self.W_O(O_t)\n",
    "\n",
    "        return u_t\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        # hidden size is 4 times the embedding size \n",
    "        hidden_size = 4 * embed_size\n",
    "        # feedforward network\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, embed_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, block_size):\n",
    "        super().__init__()\n",
    "        # multi-head attention layer (series of self-attention heads)\n",
    "        self.sa = MultiHeadLatentAttention(embed_size, num_heads, block_size)\n",
    "        self.ff = FeedForward(embed_size)\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class SimpleDeepseek(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, block_size, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        # each token directly maps to a vector\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "        # each position directly maps to a vector\n",
    "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
    "        # transformer blocks\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(embed_size, num_heads, block_size) for _ in range(num_layers)]\n",
    "        )\n",
    "        # final layer norm\n",
    "        self.ln_f = nn.LayerNorm(embed_size)\n",
    "        # final linear layer to map the embedding to the vocabulary size\n",
    "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # B: batch size, T: context length\n",
    "        B, T = idx.shape\n",
    "        # token embeddings\n",
    "        tok_embs = self.token_embedding_table(idx)                          # B, T, Emb\n",
    "        # position embeddings\n",
    "        pos_embs = self.position_embedding_table(torch.arange(T, device=idx.device))  # T, Emb\n",
    "        # add the token and position embeddings\n",
    "        x = tok_embs + pos_embs                                             # B, T, Emb\n",
    "        x = self.blocks(x)                                                  # B, T, Emb\n",
    "        x = self.ln_f(x)                                                    # B, T, Emb\n",
    "        logits = self.lm_head(x)                                            # B, T, V\n",
    "\n",
    "        # if targets is None, we are generating\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # reshape the logits and targets to be 2D\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # set the model to evaluation mode\n",
    "        self.eval()\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the context length (last block_size tokens)\n",
    "            idx_cond = idx[:, -self.position_embedding_table.num_embeddings:]\n",
    "            # get the logits and loss\n",
    "            logits, _ = self(idx_cond)\n",
    "            # get the last token\n",
    "            logits = logits[:, -1, :]\n",
    "            # get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # concatenate the new token to the context\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "\n",
    "model = SimpleDeepseek(vocab_size, embed_size, block_size, num_heads, num_layers)\n",
    "model.to(device)\n",
    "summary(model, input_data=sample_X , depth=6, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Sample Output without Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M!:QMpW3UQC'qhQLJLLP;EjdTlcQPDj!Tvy,xDWSpx3dFQUrLVE c'LLYFpPBXiOppLASwL$PJa:pdmvwXDxxeq3EHrL,$!NYWJ\n",
      "JNdJNqfoV.caqi:poKR-P-TX!FtoJTJo&'wql?TZFerQEPDVSRhHG$m iMcCXPIyQNXm,qeKWk;MhLY\n",
      "bPZDlbZ!&E'wfNH::Cvqd-GQX ciaoxTToOg.p,g$nXSPHgE::'E\n",
      "j!:saxcq-xTsVAKAPlkImlylEWkNCHlcWvKWXvedjy,vXScgdI-nCoO-pfLY!tHHfi::KYX:WSlt&$Y:UKfLMHh!YgoQVb&RhOhEBHmPAdbeGs.kNLSjhPhrQY:M.:BLPVwVFKu,dl,ghtJLpyRNDl.HDBgrxw-rLnvB\n",
      "rjPHhHhfJE3x,HE?i:EUM3!fQ\n",
      " H.QEhYdjXw!rWT:EJLgrECyWTlk-Vt dv;NApZlRrv'Qs-rdy.N&dC&w EwrM!HfVutLn:Q,bnzX$tjdDhAhLv.KW&lK.ylSdfJOvPYQT:vPZbwKChqBq$YlVvGmXQKX-kA&DFrLeB\n",
      "kTt:Z,p,OpPSNLRxp;f!QJKkk-coogXXmAKQD:Ewi,-pJh?:yFJlM WqAH JElf,hEjmLyVyb.fTDKo;SlSlQ-ahjVxLHHC!QoRnC.OWHtHq3HhJor!lyr-md&yHgHbVJE\n",
      "$JH&A fYDV:NLk squHpSJSv,dZNb.gKO HDqUofYhZf!'JP-ODhmAhx,tiAp!RhuPhnj daSRmXaP!lB,C x'SbqTXcHt&EhHdr:h3\n",
      "o!pjJn!J.I?PJOsHfYE'TokNUl?!-CmLOhLo??:DQP-LJO;vPwqcQ-xqQ LkXxqDSTSyJOOgLBuTecjYd&YGfwDWb JHt,uqbAQsYplkvDmDfHpEeGQulInlIBHvXJrbAfcthqGFEMvTLxGlCRnr,!GD-KLqxOSKOy.CVHwEWxLcmHvmN Wsqnl!X'wQduApAaDjDNiRn\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "out = model.generate(start, 1000)\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2976, val loss 4.2950\n",
      "step 1000: train loss 2.2632, val loss 2.3015\n",
      "step 2000: train loss 2.1082, val loss 2.1472\n",
      "step 3000: train loss 2.0111, val loss 2.0777\n",
      "step 4000: train loss 1.9562, val loss 2.0370\n",
      "step 5000: train loss 1.9214, val loss 2.0244\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "optimzer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_iters = 5001\n",
    "eval_interval = 1000\n",
    "eval_iters = 100\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(model, eval_iters)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    X, Y = get_batch('train')\n",
    "    logits, loss = model(X, Y)\n",
    "    optimzer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimzer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Sample Output after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "But wo home of by hims! the his andy the im the will sir; espil'in tcoingers to wor he, sick.\n",
      "\n",
      "JUMENIUS:\n",
      "For that me who was surs?\n",
      "\n",
      "TOUS:\n",
      "Shixn at op the be succh you a low; and herner at tafy a a houre soullo,\n",
      "\n",
      "Yephe fich\n",
      "He suck poten have haves boy. I well jyodly, wore ree, an contlomcul of up? I hi harse\n",
      "Provet yelland.\n",
      "\n",
      "MERCHE:\n",
      "Oo his Fupse is swarn:\n",
      "Aso your poour; which ball! Had sonmaned heie.\n",
      "\n",
      "RABENT:\n",
      "Fareer of my cery the derweer wom that him suing.3 I Ipbo Brovoneror;\n",
      "This thou of be so house,\n",
      "Live the sit ince--\n",
      "Iavin hisoher; with bure, the remanos,\n",
      "Ans his noot wouldnop your a like,\n",
      "Ye a night annot: you let\n",
      "se wor thie\n",
      "so be off I hap op the word this a not his are leasat I the lot; your that him, ta andramouse, ded rander thogy is our wels: fo gling the ating come\n",
      "And nightly loover me noblue.\n",
      "\n",
      "JULORGES:\n",
      "O where shid leep was thou musat that my hime it his prich,\n",
      "Arh'lf, ou, hip:\n",
      "Thou word: our peery, welf undip fling the lrue\n",
      "Have sh have sills;\n",
      "That more\n",
      "Let time beel\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "out = model.generate(start, 1000)\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation (MLA with RoPE positional Encoding)\n",
    "\n",
    "> Reference:-\n",
    "* [YT : How Rotary Position Embedding Supercharges Modern LLMs RoPE](https://www.youtube.com/watch?v=SMBkImDWOyQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type (var_name))                       Output Shape              Param #\n",
       "===============================================================================================\n",
       "SimpleDeepseek (SimpleDeepseek)               [32, 16, 65]              --\n",
       "├─Embedding (token_embedding_table)           [32, 16, 32]              2,080\n",
       "├─Sequential (blocks)                         [32, 16, 32]              --\n",
       "│    └─Block (0)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_QR)                [32, 16, 8]               32\n",
       "│    │    │    └─Linear (W_KR)                [32, 16, 2]               64\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "│    └─Block (1)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_QR)                [32, 16, 8]               32\n",
       "│    │    │    └─Linear (W_KR)                [32, 16, 2]               64\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "│    └─Block (2)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_QR)                [32, 16, 8]               32\n",
       "│    │    │    └─Linear (W_KR)                [32, 16, 2]               64\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "│    └─Block (3)                              [32, 16, 32]              --\n",
       "│    │    └─LayerNorm (ln1)                   [32, 16, 32]              64\n",
       "│    │    └─MultiHeadLatentAttention (sa)     [32, 16, 32]              --\n",
       "│    │    │    └─Linear (W_DQ)                [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_DKV)               [32, 16, 4]               128\n",
       "│    │    │    └─Linear (W_UQ)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UK)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_UV)                [32, 16, 32]              128\n",
       "│    │    │    └─Linear (W_QR)                [32, 16, 8]               32\n",
       "│    │    │    └─Linear (W_KR)                [32, 16, 2]               64\n",
       "│    │    │    └─Linear (W_O)                 [32, 16, 32]              1,024\n",
       "│    │    └─LayerNorm (ln2)                   [32, 16, 32]              64\n",
       "│    │    └─FeedForward (ff)                  [32, 16, 32]              --\n",
       "│    │    │    └─Sequential (net)             [32, 16, 32]              --\n",
       "│    │    │    │    └─Linear (0)              [32, 16, 128]             4,224\n",
       "│    │    │    │    └─GELU (1)                [32, 16, 128]             --\n",
       "│    │    │    │    └─Linear (2)              [32, 16, 32]              4,128\n",
       "├─LayerNorm (ln_f)                            [32, 16, 32]              64\n",
       "├─Linear (lm_head)                            [32, 16, 65]              2,145\n",
       "===============================================================================================\n",
       "Total params: 45,249\n",
       "Trainable params: 45,249\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.45\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 6.59\n",
       "Params size (MB): 0.18\n",
       "Estimated Total Size (MB): 6.78\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class MultiHeadLatentAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, block_size):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_size = embed_size\n",
    "        self.block_size = block_size\n",
    "        self.head_size = embed_size // num_heads # 32 / 8 = 4\n",
    "        self.latent_size = embed_size // 8 # 32 / 8 = 4\n",
    "        self.r_head_size = max(2, self.head_size // 4)\n",
    "\n",
    "        # Down-Project (embed_size -> latent_size) : Shared across heads\n",
    "        self.W_DQ = nn.Linear(embed_size, self.latent_size, bias=False)\n",
    "        self.W_DKV = nn.Linear(embed_size, self.latent_size, bias=False)\n",
    "\n",
    "        # (Concatenated (head_size * num_heads) -> embed_size) : Shared across heads\n",
    "        self.W_O = nn.Linear(self.head_size * num_heads, embed_size, bias=False)\n",
    "\n",
    "        # Up-Project (latent_size -> head_size) * num_heads : Head specific\n",
    "        self.W_UQ = nn.Linear(self.latent_size, self.head_size * num_heads, bias=False)\n",
    "        self.W_UK = nn.Linear(self.latent_size, self.head_size * num_heads, bias=False)\n",
    "        self.W_UV = nn.Linear(self.latent_size, self.head_size * num_heads, bias=False)\n",
    "\n",
    "        # Rope Carriers\n",
    "        self.W_QR = nn.Linear(self.latent_size, self.r_head_size * num_heads, bias=False) # Head specific\n",
    "        self.W_KR = nn.Linear(self.embed_size, self.r_head_size, bias=False) # Shared across heads\n",
    "\n",
    "        # Masking : Shared across heads\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.d_sqrt_full = (self.r_head_size + self.head_size) ** 0.5\n",
    "\n",
    "    def rotary_sin_cos(self, seq_len, base = 10000.0, device=None):\n",
    "        if device is None:\n",
    "            device = self.tril.device\n",
    "        t = torch.arange(seq_len, device=device, dtype=torch.float32)\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, self.r_head_size, 2, device=device, dtype=torch.float32) / self.r_head_size))\n",
    "        freqs = torch.einsum(\"t,f->tf\", t, inv_freq)\n",
    "        return freqs.sin(), freqs.cos()\n",
    "\n",
    "    def apply_rope(self, x, cos, sin):\n",
    "        # x: B, H, T, D\n",
    "        x1 = x[..., ::2] # B, H, T, D/2\n",
    "        x2 = x[..., 1::2] # B, H, T, D/2\n",
    "        sin = sin.unsqueeze(0).unsqueeze(0)  # 1, 1, T, D/2\n",
    "        cos = cos.unsqueeze(0).unsqueeze(0)  # 1, 1, T, D/2\n",
    "        x1_new = (x1 * cos) - (x2 * sin) # B, H, T, D/2\n",
    "        x2_new = (x1 * sin) + (x2 * cos) # B, H, T, D/2\n",
    "        return torch.stack((x1_new, x2_new), dim=-1).reshape(x.shape) # B, H, T, D\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, Emb = x.shape\n",
    "\n",
    "        # Down-Project (embed_size -> latent_size)\n",
    "        c_Qt = self.W_DQ(x) # B, T, latent_size\n",
    "        c_KVt = self.W_DKV(x) # B, T, latent_size\n",
    "\n",
    "        # Up-Project (latent_size -> head_size) * num_heads\n",
    "        q_Cti = self.W_UQ(c_Qt).view(B, T, self.num_heads, self.head_size) # B, T, num_heads, head_size\n",
    "        k_Cti = self.W_UK(c_KVt).view(B, T, self.num_heads, self.head_size) # B, T, num_heads, head_size\n",
    "        v_Cti = self.W_UV(c_KVt).view(B, T, self.num_heads, self.head_size) # B, T, num_heads, head_size\n",
    "\n",
    "        # Rope Carriers\n",
    "        # Per Head\n",
    "        q_Rti = self.W_QR(c_Qt).view(B, T, self.num_heads, self.r_head_size) # B, T, num_heads, r_head_size\n",
    "        # Shared across heads\n",
    "        k_R = self.W_KR(x) # B, T, r_head_size\n",
    "        k_Rti = k_R.unsqueeze(2).expand(B, T, self.num_heads, self.r_head_size) # B, T, num_heads, r_head_size\n",
    "\n",
    "        # (B, T, num_heads, head_size) -> (B, num_heads, T, head_size) for QK matrix multiplication\n",
    "        q_Cti = q_Cti.permute(0, 2, 1, 3)\n",
    "        k_Cti = k_Cti.permute(0, 2, 1, 3)\n",
    "        v_Cti = v_Cti.permute(0, 2, 1, 3)\n",
    "        q_Rti = q_Rti.permute(0, 2, 1, 3)\n",
    "        k_Rti = k_Rti.permute(0, 2, 1, 3)\n",
    "\n",
    "        # Apply Rope\n",
    "        cos, sin = self.rotary_sin_cos(T)\n",
    "        q_Rti = self.apply_rope(q_Rti, cos, sin)\n",
    "        k_Rti = self.apply_rope(k_Rti, cos, sin)\n",
    "\n",
    "        # Concatenate context and rope carriers\n",
    "        q_full = torch.cat((q_Cti, q_Rti), dim=-1) # B, T, num_heads, head_size + r_head_size\n",
    "        k_full = torch.cat((k_Cti, k_Rti), dim=-1) # B, T, num_heads, head_size + r_head_size\n",
    "\n",
    "        # Attention : QK^T / sqrt(head_size)\n",
    "        att = (q_full @ k_full.transpose(-2, -1)) / self.d_sqrt_full # B, num_heads, T, T\n",
    "        att = att.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        O_ti = att @ v_Cti # B, num_heads, T, head_size\n",
    "\n",
    "        # B, num_heads, T, head_size -> B, T, num_heads, head_size -> B, T, embed_size\n",
    "        O_t = O_ti.permute(0, 2, 1, 3).reshape(B, T, -1)\n",
    "        # (Concatenated (heads * head_size) -> embed_size)\n",
    "        u_t = self.W_O(O_t)\n",
    "\n",
    "        return u_t\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        # hidden size is 4 times the embedding size \n",
    "        hidden_size = 4 * embed_size\n",
    "        # feedforward network\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, embed_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, block_size):\n",
    "        super().__init__()\n",
    "        # multi-head attention layer (series of self-attention heads)\n",
    "        self.sa = MultiHeadLatentAttention(embed_size, num_heads, block_size)\n",
    "        self.ff = FeedForward(embed_size)\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class SimpleDeepseek(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, block_size, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        # each token directly maps to a vector\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "        # transformer blocks\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(embed_size, num_heads, block_size) for _ in range(num_layers)]\n",
    "        )\n",
    "        # final layer norm\n",
    "        self.ln_f = nn.LayerNorm(embed_size)\n",
    "        # final linear layer to map the embedding to the vocabulary size\n",
    "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # B: batch size, T: context length\n",
    "        B, T = idx.shape\n",
    "        # token embeddings\n",
    "        x = self.token_embedding_table(idx)                          # B, T, Emb\n",
    "        x = self.blocks(x)                                                  # B, T, Emb\n",
    "        x = self.ln_f(x)                                                    # B, T, Emb\n",
    "        logits = self.lm_head(x)                                            # B, T, V\n",
    "\n",
    "        # if targets is None, we are generating\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # reshape the logits and targets to be 2D\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # set the model to evaluation mode\n",
    "        self.eval()\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the context length (last block_size tokens)\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            # get the logits and loss\n",
    "            logits, _ = self(idx_cond)\n",
    "            # get the last token\n",
    "            logits = logits[:, -1, :]\n",
    "            # get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # concatenate the new token to the context\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "\n",
    "model = SimpleDeepseek(vocab_size, embed_size, block_size, num_heads, num_layers)\n",
    "model.to(device)\n",
    "summary(model, input_data=sample_X , depth=6, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Sample Output after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3412, val loss 4.3360\n",
      "step 1000: train loss 2.2124, val loss 2.2435\n",
      "step 2000: train loss 2.0881, val loss 2.1416\n",
      "step 3000: train loss 2.0014, val loss 2.0856\n",
      "step 4000: train loss 1.9633, val loss 2.0492\n",
      "step 5000: train loss 1.9185, val loss 2.0353\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "optimzer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_iters = 5001\n",
    "eval_interval = 1000\n",
    "eval_iters = 100\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(model, eval_iters)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    X, Y = get_batch('train')\n",
    "    logits, loss = model(X, Y)\n",
    "    optimzer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimzer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ay, sed the awee royay,'dages Wink I wast.\n",
      "Mas as this greant laing\n",
      "Hs thee.\n",
      "QUTABELour IFs, in moulsue depord Ed as an yevexare\n",
      "Thenderaged of Muusoul ay. fick\n",
      "Toptih Wipty aloght,\n",
      "it heat plan a ioun;\n",
      "Yor, who nondly me thouglang?\n",
      "\n",
      "LERENCE:\n",
      "Oncury nowip wet sw ondle, thre.\n",
      "\n",
      "KING HERY werear,\n",
      "I'enge no go, thic!\n",
      "\n",
      "And paser, of take up of minspectencery so, they dime that one shing thall may hEBENCHBRCARLARKE:\n",
      "Say, piend it a\n",
      "Dis entest hoir!\n",
      "Mlakes, home! than and wame thill--dring pupt, and beo,\n",
      "Of a you,\n",
      "toou ueg.\n",
      "\n",
      "LAUTI Call no his hat merie hord good sepowed hy thy rold'd the breart made\n",
      "Or you;\n",
      "Of but-sea heir portin thened:\n",
      "Whose or frect; shiled, proy, Hoods;\n",
      "That sus your bat lot his will bobow lethinguens\n",
      "Thy so Of throw he cansty ste clood of ar bread.\n",
      "\n",
      "Sot lark demph of Beat wid, hous toan, now kif;\n",
      "Where, so all insitione?\n",
      "\n",
      "CORIGASCAMIONAOMIY:\n",
      "And sols shall sug anore.\n",
      "Bold my wolld, me;\n",
      "From to hont oftaina-wite foth with shom woult a so.\n",
      "3\n",
      "LANG's they that kno him my soa\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "out = model.generate(start, 1000)\n",
    "print(decode(out[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
